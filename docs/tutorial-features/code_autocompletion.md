---
sidebar_position: 2
---

# Autocomplete

The Autocomplete feature empowers you to choose from a curated selection of models, including those from Mistral and Ollama. This advanced tool enhances your coding experience by providing accurate and contextually relevant code suggestions.

## How to Use:
- Go to Menu on CodeGPT sidebar:
    - Click on the **Autocomplete** option
    - Check the Status
    - Choose the AI model
    - **Provider:**
        - CodeGPT Plus
        - CodeGPT Plus-turbo
        - Mistral-codestral-latest
        - Ollama-qwen2.5-code:0.5b
        - Ollama-qwen2.5-code:1.5b
        - Ollama-qwen2.5-code:3b
        - Ollama qwen2.5-code:7b
        - Ollama-qwen2.5-code:14b
        - Ollama-qwen2.5-code:32b
        - Ollama deepseeek-coder:base
        - Ollama deepseek-coder-v2
        - Ollama codellama:code
        - Ollama codegemma:code
          
    - ⚠️**IMPORTANT**⚠️: Ensure that Ollama is running locally and that the model you are using is properly installed. For Mistral Codestral, insert the API Key and set Mistral as the main provider.
    - By default, the AI model determines the maximum number of tokens. Please refer to each provider's documentation for specific details. Additionally, the suggestion is generated with a delay of 3000 milliseconds.

:::note Autocomplete settings
<p align="center">
      <img width="200" height="350" src="https://github.com/user-attachments/assets/2248e837-c4aa-40ac-8afd-4fb3971f3dae" />
</p>
:::

- Effortless Integration: Seamlessly incorporate the suggested code snippets into your project, improving code quality and efficiency. Press `Tab` to accept the suggestion.


:::note Autocomplete
<p align="center">
      <img width="750" height="550" src="https://github.com/user-attachments/assets/569560e6-588f-4e42-8a8c-032363cd2196" />
</p>

:::
